image: docker:latest

services:
  - docker:dind

stages:
  # - esimport_retention
  - build_ecs_image
  - build
  - testing
  - staging_deploy
  - production_deploy

# When using dind, it's wise to use the overlayfs driver for improved performance.
variables:
  DOCKER_DRIVER: overlay
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
  DOCKER_HOST: "tcp://docker:2375"

before_script:
  - mkdir ~/.aws/
  - printf "[default]\nregion=us-west-2\n" > ~/.aws/config
  - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
  - pip3 --no-cache-dir install awscli awsebcli
  - curl -fsSL https://get.docker.com -o get-docker.sh
  - sh get-docker.sh
  - docker info
  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY

build_base_image:
  stage: build
  script:
    - docker build -t $IMAGE_TAG -f base.Dockerfile .
    - docker push $IMAGE_TAG
  only:
    - base

build_ecs_image_dev:
  stage: build_ecs_image
  image:
    name: docker:latest
  before_script:
    - echo "export AWS_DEFAULT_REGION=us-west-2" > variables-dev
    - echo "export KEY_NAME=eleven-deploy" >> variables-dev
    - echo "export REPOSITORY_NAME=esimport" >> variables-dev
    - echo "export AWS_ACCESS_KEY_ID=$dev_AWS_ACCESS_KEY_ID" >> variables-dev
    - echo "export AWS_SECRET_ACCESS_KEY=$dev_AWS_SECRET_ACCESS_KEY" >> variables-dev

  script:
    - |
      apk add --update --no-cache aws-cli
      
      source ./variables-dev
      
      if [ -z "$CI_COMMIT_SHA" ]; then
          export CI_COMMIT_SHA=$(git rev-parse HEAD)
      fi
      
      export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
      
      export ElevenApiEcrRepositoryUri=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$REPOSITORY_NAME
      export IMAGE_TAG=$ElevenApiEcrRepositoryUri:$CI_COMMIT_SHA
      
      docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
      docker build -t $IMAGE_TAG .
      
      # login after building image because image need access to base image that stored in gilab registry
      echo $(aws ecr get-login-password --region us-west-2) | docker login --password-stdin --username AWS $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com

      docker push $IMAGE_TAG
      echo $IMAGE_TAG

  when: manual

build_image:
  stage: build
  script:
    - mkdir .elasticbeanstalk && echo "$EB_PROD_WEST_CONFIG" > .elasticbeanstalk/config.yml
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - aws s3 cp s3://dataservices.esimport.production/msodbc.ini.prod.west msodbc.ini
    - docker build -t $IMAGE_TAG -f prod.Dockerfile .
    - docker push $IMAGE_TAG

staging_deploy:
  stage: staging_deploy
  script:
    - apk add --update --no-cache gcc python3-dev musl-dev libffi-dev build-base openssl-dev git
    - pip3 --no-cache-dir install awsebcli awscli
    - mkdir ~/.aws/
    - aws s3 cp s3://dataservices.esimport/local_settings.py.stag local_settings.py
    - aws s3 cp s3://dataservices.esimport/msodbc.ini.stag msodbc.ini
    - eb deploy $EB_STAGING_ENV_NAME --verbose
  only:
    - develop
  when: manual

production_deploy:
  stage: production_deploy
  script:
    - mkdir .elasticbeanstalk && echo "$EB_PROD_WEST_CONFIG" > .elasticbeanstalk/config.yml
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - eb labs cleanup-versions --num-to-leave 50 --force # cleanup old versions
    - eb deploy $PROD_EB_ENV_NAME --verbose
  only:
    - master
  when: manual

esimport_testing:
  stage: testing
  only:
    - branches
    - tags
    - pushes
    - merge_requests
  except:
    - base
  before_script:
    - apk add --update --no-cache docker-compose make
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
  script:
    - cp .env-example .env
    - . .env
    - make test
  coverage: '/TOTAL\s+\d+\s+\d+\s+\d+\s+\d+\s+(\d+%)/'

# TODO: Activate the following stages when esimport is deployed as a serverless app
# esimport_datadog_integration_test:
#   stage: testing
#   when: manual
#   before_script:
#     - pwd # canceling global before_script, it does not needed for this job
#   services:
#     - docker:dind
#     - name: docker.elastic.co/elasticsearch/elasticsearch:5.3.3
#       alias: es
#       entrypoint: ["bin/elasticsearch"]
#       command: ["-Ehttp.host=0.0.0.0", "-Etransport.host=127.0.0.1", "-Expack.security.enabled=false"]
#   variables:
#     LOOK_BACK_FOR_X_MINUTES: 1
#     ES_URL: "https://fake-will-not-be-used.us-west-2.es.amazonaws.com/"
#     TEST_ES_HOST: 'es'
#     AWS_ACCESS_KEY_ID: fake
#     AWS_SECRET_ACCESS_KEY: fake
#     AWS_SESSION_TOKEN: fake

#   script:
#     - apk add --no-cache bash python3
#     - cd esimport_datadog
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - >
#       python3 -m pytest
#       -x
#       --cov=esimport_datadog
#       --cov-report=term-missing
#       tests
#   coverage: '/esimport_datadog.py\s+\d+\s+\d+\s+(\d+%)/'

esimport_datadog_deploy:
  stage: production_deploy
  when: manual
  script:
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - printf "[default]\nregion=us-west-2\n" > ~/.aws/config
    - pip3 --no-cache-dir install awscli aws-sam-cli
    - cd lambdas/esimport_datadog
    # WEST deploy
    - bash ./deploy.sh
      esimport-datadog-monitor-us-west-2
      ${PROD_LAMBDA_S3_BUCKET_WEST}
      ${PROD_DATADOG_LOOKBACK_X_MINUTES}
      ${PROD_ES_CLUSTER_WEST}
      ${SENTRY_DSN}
      ${PROD_DATADOG_API_KEY}
      us-west-2
      ${PROD_ROLE_ARN}
    # EAST deploy
    - bash ./deploy.sh
      esimport-datadog-monitor-us-east-1
      ${PROD_LAMBDA_S3_BUCKET_EAST}
      ${PROD_DATADOG_LOOKBACK_X_MINUTES}
      ${PROD_ES_CLUSTER_EAST}
      ${SENTRY_DSN}
      ${PROD_DATADOG_API_KEY}
      us-east-1
      ${PROD_ROLE_ARN}
# esimport_retention_unit_test:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - >
#       python3 -m pytest tests/unit_tests -x
#       --cov=esimport_retention_core
#       --cov-report=term-missing
#   coverage: '/esimport_retention_core.py\s+\d+\s+\d+\s+(\d+%)/'

# esimport_retention_integration_test:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install awscli
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - bash run-integration-tests.sh
#   coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'

# esimport_retention_deploy:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install awscli
#     - >
#       bash ./deploy.sh \
#       <CloudFormation stack name> \
#       <S3 Bucket Name, to store lambda function code> \
#       <Retention policy in months> \
#       <ES endpoints/urls, comma separated strings> \
#       <Sentry dsn> \
#       <Indices prefixes, comma separated strings> \
#       <Snapshot repo name>
#       <Desired LOGLEVEl>
