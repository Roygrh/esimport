image: docker:latest
services:
  - docker:dind

stages:
  - testing
  - build
  - staging_deploy
  - production_west_deploy
  - production_east_deploy
  - esimport_datadog_deploy

# When using dind, it's wise to use the overlayfs driver for improved performance.
variables:
  DOCKER_DRIVER: overlay
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG

before_script:
  - apk add --update --no-cache python3 git wget
  - pip3 --no-cache-dir install awsebcli awscli
  - mkdir ~/.aws/
  - wget https://packages.microsoft.com/rhel/7/prod/msodbcsql17-17.3.1.1-1.x86_64.rpm -O msodbcsql17.rpm
  - wget http://mirror.centos.org/centos/7/os/x86_64/Packages/unixODBC-2.3.1-11.el7.x86_64.rpm -O unixODBC.rpm
  - wget http://mirror.centos.org/centos/7/os/x86_64/Packages/unixODBC-devel-2.3.1-11.el7.x86_64.rpm -O unixODBC-devel.rpm

build:
  stage: build
  before_script:
    - docker info
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
  script:
    - docker build -t $IMAGE_TAG .
    - docker push $IMAGE_TAG
  allow_failure: true # TODO: change/remove this if prod/staging are/will be using the docker image

staging_deploy:
  stage: staging_deploy
  script:
    - mkdir .elasticbeanstalk && echo "$EB_STAGING_CONFIG" > .elasticbeanstalk/config.yml
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_STAGING_ACCESS_KEY_ID" "$EB_STAGING_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - printf "[default]\nregion=us-east-1\n" > ~/.aws/config
    - aws s3 cp s3://dataservices.esimport/local_settings.py.stag local_settings.py
    - aws s3 cp s3://dataservices.esimport/msodbc.ini.stag msodbc.ini
    - eb deploy $EB_STAGING_ENV_NAME --verbose
  only:
    - develop
  when: manual

production_west_deploy:
  stage: production_west_deploy
  script:
    - mkdir .elasticbeanstalk && echo "$EB_PROD_WEST_CONFIG" > .elasticbeanstalk/config.yml
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - printf "[default]\nregion=us-west-2\n" > ~/.aws/config
    - aws s3 cp s3://dataservices.esimport.production/local_settings.py.prod.west local_settings.py
    - aws s3 cp s3://dataservices.esimport.production/msodbc.ini.prod.west msodbc.ini
    - eb deploy $EB_PROD_WEST_ENV_NAME --verbose
  only:
    - master
  when: manual

production_east_deploy:
  stage: production_east_deploy
  script:
    - mkdir .elasticbeanstalk && echo "$EB_PROD_EAST_CONFIG" > .elasticbeanstalk/config.yml
    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
    - printf "[default]\nregion=us-east-1\n" > ~/.aws/config
    - aws s3 cp s3://dataservices.esimport.production/local_settings.py.prod.east local_settings.py
    - aws s3 cp s3://dataservices.esimport.production/msodbc.ini.prod.east msodbc.ini
    - eb deploy $EB_PROD_EAST_ENV_NAME --verbose
  only:
    - master
  when: manual

esimport_datadog_integration_test:
  stage: testing
  when: manual
  before_script:
    - pwd # canceling global before_script, it does not needed for this job
  services:
    - docker:dind
    - name: docker.elastic.co/elasticsearch/elasticsearch:5.3.3
      alias: es
      entrypoint: ["bin/elasticsearch"]
      command: ["-Ehttp.host=0.0.0.0", "-Etransport.host=127.0.0.1", "-Expack.security.enabled=false"]
  variables:
    LOOK_BACK_FOR_X_MINUTES: 1
    ES_URL: "https://fake-will-not-be-used.us-west-2.es.amazonaws.com/"
    TEST_ES_HOST: 'es'
    AWS_ACCESS_KEY_ID: fake
    AWS_SECRET_ACCESS_KEY: fake
    AWS_SESSION_TOKEN: fake

  script:
    - apk add --no-cache bash python3
    - cd esimport_datadog
    - pip3 install -r ./requirements.txt
    - pip3 install -r ./dev-requirements.txt
    - >
      python3 -m pytest
      -x
      --cov=esimport_datadog
      --cov-report=term-missing
      tests
  coverage: '/esimport_datadog.py\s+\d+\s+\d+\s+(\d+%)/'

esimport_datadog_deploy:
  stage: esimport_datadog_deploy
  when: manual
  before_script:
    - apk add --update --no-cache python3 zip bash
    - pip3 --no-cache-dir install awscli

  script:
    - cd esimport_datadog
    - >
      bash ./deploy.sh \
      <CloudFormation stack name> \
      <S3 bucket to store lambda function deploy archive> \
      <Number in minutes, that will be used to in queries to search last inserted doc > \
      <ElasticsSearch server/cluser url> \
      <DSN for Sentry> \
      <Datadog API key> \
      <Datadog host_name \
      INFO
