image: ubuntu:20.04

services:
  - docker:20.10.16-dind

stages:
  # - esimport_retention
  #  - build
  - testing
  #  - staging_deploy
  - production_deploy
  - build_ecs_image
  - deploy_ecs_image_staging
  - deploy_ecs_image_prod

# When using dind, it's wise to use the overlayfs driver for improved performance.
variables:
  DOCKER_DRIVER: overlay
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG

before_script:
  - mkdir ~/.aws/
  - printf "[default]\nregion=us-west-2\n" > ~/.aws/config
  - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
  - pip3 --no-cache-dir install awscli awsebcli
  - curl -fsSL https://get.docker.com -o get-docker.sh
  - sh get-docker.sh
  - docker info
  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY

#build_base_image:
#  stage: build
#  script:
#    - docker build -t $IMAGE_TAG -f base.Dockerfile .
#    - docker push $IMAGE_TAG
#  only:
#    - base

build_ecs_image_dev:
  stage: build_ecs_image
  image:
    name: docker:latest
  before_script:
    - echo "export AWS_DEFAULT_REGION=us-west-2" > variables-dev
    - echo "export KEY_NAME=eleven-deploy" >> variables-dev
    - echo "export REPOSITORY_NAME=esimport" >> variables-dev
    - echo "export AWS_ACCESS_KEY_ID=$dev_AWS_ACCESS_KEY_ID" >> variables-dev
    - echo "export AWS_SECRET_ACCESS_KEY=$dev_AWS_SECRET_ACCESS_KEY" >> variables-dev

  script:
    - |
      apk add --update --no-cache aws-cli bash

      source ./variables-dev

      docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
      bash ./ecs_build_and_upload_ecr.sh

  when: manual

build_ecs_image_staging:
  stage: build_ecs_image
  image:
    name: docker:latest
  before_script:
    - echo "export AWS_DEFAULT_REGION=us-west-2" > variables-staging
    - echo "export KEY_NAME=eleven-deploy" >> variables-staging
    - echo "export REPOSITORY_NAME=esimport" >> variables-staging
    - echo "export AWS_ACCESS_KEY_ID=$staging_AWS_ACCESS_KEY_ID" >> variables-staging
    - echo "export AWS_SECRET_ACCESS_KEY=$staging_AWS_SECRET_ACCESS_KEY" >> variables-staging

  script:
    - |
      apk add --update --no-cache aws-cli bash
      cat ./variables-staging
      source ./variables-staging

      docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
      bash ./ecs_build_and_upload_ecr.sh

  #  when: manual
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"
    - if: $CI_COMMIT_BRANCH == "branch_for_staging" || $CI_COMMIT_BRANCH == "master"

build_ecs_image_production:
  stage: build_ecs_image
  image:
    name: docker:latest
  before_script:
    - echo "export AWS_DEFAULT_REGION=us-west-2" > variables-prod
    - echo "export KEY_NAME=eleven-deploy" >> variables-prod
    - echo "export REPOSITORY_NAME=esimport" >> variables-prod
    - echo "export AWS_ACCESS_KEY_ID=$prod_AWS_ACCESS_KEY_ID" >> variables-prod
    - echo "export AWS_SECRET_ACCESS_KEY=$prod_AWS_SECRET_ACCESS_KEY" >> variables-prod

  script:
    - |
      apk add --update --no-cache aws-cli bash
      cat ./variables-prod
      source ./variables-prod

      docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
      bash ./ecs_build_and_upload_ecr.sh
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"
    - if: $CI_COMMIT_BRANCH == "master"

#  when: manual

#build_image:
#  stage: build
#  script:
#    - mkdir .elasticbeanstalk && echo "$EB_PROD_WEST_CONFIG" > .elasticbeanstalk/config.yml
#    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
#    - aws s3 cp s3://dataservices.esimport.production/msodbc.ini.prod.west msodbc.ini
#    - docker build -t $IMAGE_TAG -f prod.Dockerfile .
#    - docker push $IMAGE_TAG
#  only:
#    - master

#staging_deploy:
#  stage: staging_deploy
#  script:
#    - apk add --update --no-cache gcc python3-dev musl-dev libffi-dev build-base openssl-dev git
#    - pip3 --no-cache-dir install awsebcli awscli
#    - mkdir ~/.aws/
#    - aws s3 cp s3://dataservices.esimport/local_settings.py.stag local_settings.py
#    - aws s3 cp s3://dataservices.esimport/msodbc.ini.stag msodbc.ini
#    - eb deploy $EB_STAGING_ENV_NAME --verbose
#  only:
#    - develop
#  when: manual

#production_deploy:
#  stage: production_deploy
#  script:
#    - mkdir .elasticbeanstalk && echo "$EB_PROD_WEST_CONFIG" > .elasticbeanstalk/config.yml
#    - printf "[default]\naws_access_key_id = %s\naws_secret_access_key = %s\n" "$EB_PROD_ACCESS_KEY_ID" "$EB_PROD_SECRET_ACCESS_KEY" >> ~/.aws/credentials
#    - eb labs cleanup-versions --num-to-leave 50 --force # cleanup old versions
#    - eb deploy $PROD_EB_ENV_NAME --verbose
#  only:
#    - master
#  when: manual

esimport_testing:
  stage: testing
  image:
    name: docker:latest
  only:
    - merge_requests
  except:
    - base
  before_script:
    - apk add --update --no-cache docker-compose make
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
  script:
    - cp .env-example .env
    - . .env
    - cat .env
    - env
    - make test
  coverage: '/TOTAL\s+\d+\s+\d+\s+\d+\s+\d+\s+(\d+%)/'

deploy_esc_staging:
  stage: deploy_ecs_image_staging
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli awsebcli
    - curl -fsSL https://get.docker.com -o get-docker.sh
    - sh get-docker.sh

    # us-east-1 region where staging-db04.11os.com and it's VPC is located
    - echo "export AWS_DEFAULT_REGION=us-east-1" > variables-staging
    - echo "export AWS_ACCESS_KEY_ID=$staging_AWS_ACCESS_KEY_ID" >> variables-staging
    - echo "export AWS_SECRET_ACCESS_KEY=$staging_AWS_SECRET_ACCESS_KEY" >> variables-staging
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$staging_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-staging

    - echo "export DATABASE_CALLS_WAIT_IN_SECONDS=$staging_DATABASE_CALLS_WAIT_IN_SECONDS" >> variables-staging
    - echo "export DATABASE_QUERY_TIMEOUT=$staging_DATABASE_QUERY_TIMEOUT" >> variables-staging

    # DSN config name. Uses "Eleven_OS" value if inside Docker conatiner (check config.py ) or specified value if outside
    - echo "export DSN=$staging_DSN" >> variables-staging
    - echo "export LOG_LEVEL=$staging_LOG_LEVEL" >> variables-staging
    - echo "export MSSQL_DSN=$staging_MSSQL_DSN" >> variables-staging

    # is used in odbc.ini file
    - echo "export MSSQL_HOST=$staging_MSSQL_HOST" >> variables-staging
    - echo "export MSSQL_USER=$staging_MSSQL_USER" >> variables-staging
    - echo "export MSSQL_PASSWORD=$staging_MSSQL_PASSWORD" >> variables-staging
    - echo "export PPK_SQS_QUEUE_URL=$staging_PPK_SQS_QUEUE_URL" >> variables-staging
    - echo "export PPK_SQS_QUEUE_ARN=$staging_PPK_SQS_QUEUE_ARN" >> variables-staging
    - echo "export PPK_DLQ_QUEUE_URL=$staging_PPK_DLQ_QUEUE_URL" >> variables-staging
    - echo "export PPK_DLQ_QUEUE_ARN=$staging_PPK_DLQ_QUEUE_ARN" >> variables-staging
    - echo "export REDIS_HOST=$staging_REDIS_HOST" >> variables-staging
    - echo "export REDIS_PORT=$staging_REDIS_PORT" >> variables-staging
    - echo "export SENTRY_DSN=$staging_SENTRY_DSN" >> variables-staging
    - echo "export SNS_TOPIC_ARN=$staging_SNS_TOPIC_ARN" >> variables-staging

    # ssh-key
    - echo "export KEY_NAME=shared_esimport_dev_ecs" >> variables-staging
    - echo "export REPOSITORY_NAME=esimport" >> variables-staging

    - echo "export ESImportEcrRepositoryUri=$ESImportEcrRepositoryUri" >> variables-staging
    # subnet where DB instance staging-db04.11os.com located
    - echo "export InstancesSbunet=subnet-24220141" >> variables-staging
    # VPC where DB instance staging-db04.11os.com located
    - echo "export VPC_ID=vpc-88a043f1" >> variables-staging

  script:
    - |

      source ./variables-staging

      if [ -z "$CI_COMMIT_SHA" ]; then
          export CI_COMMIT_SHA=$(git rev-parse HEAD)
      fi

      repo_region="us-west-2"
      export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)

      export esimport_docker_repo_url=$AWS_ACCOUNT_ID.dkr.ecr.$repo_region.amazonaws.com/$REPOSITORY_NAME
      export IMAGE_TAG=$esimport_docker_repo_url:$CI_COMMIT_SHA

      export IMAGE_TO_DEPLOY=$esimport_docker_repo_url:$CI_COMMIT_SHA

      bash ./ecs_build_deploy.sh $IMAGE_TO_DEPLOY
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"
    - if: $CI_COMMIT_BRANCH == "branch_for_staging" || $CI_COMMIT_BRANCH == "master"

deploy_esc_prod:
  stage: deploy_ecs_image_prod
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli
    - curl -fsSL https://get.docker.com -o get-docker.sh
    - sh get-docker.sh

    - echo "export AWS_DEFAULT_REGION=$prod_AWS_DEFAULT_REGION" > variables-prod

    # account from Monolith Prod that has permission to deploy `distrodev-deployer`
    - echo "export AWS_ACCESS_KEY_ID=$prod_AWS_ACCESS_KEY_ID" >> variables-prod
    - echo "export AWS_SECRET_ACCESS_KEY=$prod_AWS_SECRET_ACCESS_KEY" >> variables-prod
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$prod_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-prod

    - echo "export DATABASE_CALLS_WAIT_IN_SECONDS=$prod_DATABASE_CALLS_WAIT_IN_SECONDS" >> variables-prod
    - echo "export DATABASE_QUERY_TIMEOUT=$prod_DATABASE_QUERY_TIMEOUT" >> variables-prod

    # DSN config name. Uses "Eleven_OS" value if inside Docker conatiner (check config.py ) or specified value if outside
    - echo "export DSN=$prod_DSN" >> variables-prod
    - echo "export LOG_LEVEL=$prod_LOG_LEVEL" >> variables-prod
    - echo "export MSSQL_DSN=$prod_MSSQL_DSN" >> variables-prod

    # is used in odbc.ini file
    - echo "export MSSQL_HOST=$prod_MSSQL_HOST" >> variables-prod
    - echo "export MSSQL_USER=$prod_MSSQL_USER" >> variables-prod
    - echo "export MSSQL_PASSWORD=$prod_MSSQL_PASSWORD" >> variables-prod
    - echo "export PPK_SQS_QUEUE_URL=$prod_PPK_SQS_QUEUE_URL" >> variables-prod
    - echo "export PPK_SQS_QUEUE_ARN=$prod_PPK_SQS_QUEUE_ARN" >> variables-prod
    - echo "export PPK_DLQ_QUEUE_URL=$prod_PPK_DLQ_QUEUE_URL" >> variables-prod
    - echo "export PPK_DLQ_QUEUE_ARN=$prod_PPK_DLQ_QUEUE_ARN" >> variables-prod
    - echo "export REDIS_HOST=$prod_REDIS_HOST" >> variables-prod
    - echo "export REDIS_PORT=$prod_REDIS_PORT" >> variables-prod
    - echo "export SENTRY_DSN=$prod_SENTRY_DSN" >> variables-prod
    - echo "export SNS_TOPIC_ARN=$prod_SNS_TOPIC_ARN" >> variables-prod

    # ssh-key
    - echo "export KEY_NAME=$prod_ESIMPORT_SSH_KEY" >> variables-prod
    - echo "export REPOSITORY_NAME=esimport" >> variables-prod

    - echo "export ESImportEcrRepositoryUri=$ESImportEcrRepositoryUri" >> variables-prod
    # subnet where DB instance staging-db04.11os.com located
    - echo "export InstancesSbunet=$prod_INSTANCES_SUBNET" >> variables-prod
    # VPC where DB instance staging-db04.11os.com located
    - echo "export VPC_ID=$prod_VPC" >> variables-prod
    - echo "export DATADOG_API_KEY=$prod_DATADOG_API_KEY" >> variables-prod
    - echo "export DATADOG_ENV=$prod_DATADOG_ENV" >> variables-prod

  script:
    - |

      source ./variables-prod
      export VENDOR_DEFAULT_REGION="us-west-2"
      export VENDOR_ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)

      if [ -z "$CI_COMMIT_SHA" ]; then
          export CI_COMMIT_SHA=$(git rev-parse HEAD)
      fi

      export ElevenApiEcrRepositoryUri=$VENDOR_ACCOUNT_ID.dkr.ecr.$VENDOR_DEFAULT_REGION.amazonaws.com/$REPOSITORY_NAME
      export IMAGE_TO_DEPLOY=$ElevenApiEcrRepositoryUri:$CI_COMMIT_SHA
      bash ./ecs_build_deploy.sh $IMAGE_TO_DEPLOY

  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "master"

# TODO: Activate the following stages when esimport is deployed as a serverless app
# esimport_datadog_integration_test:
#   stage: testing
#   when: manual
#   before_script:
#     - pwd # canceling global before_script, it does not needed for this job
#   services:
#     - docker:dind
#     - name: docker.elastic.co/elasticsearch/elasticsearch:5.3.3
#       alias: es
#       entrypoint: ["bin/elasticsearch"]
#       command: ["-Ehttp.host=0.0.0.0", "-Etransport.host=127.0.0.1", "-Expack.security.enabled=false"]
#   variables:
#     LOOK_BACK_FOR_X_MINUTES: 1
#     ES_URL: "https://fake-will-not-be-used.us-west-2.es.amazonaws.com/"
#     TEST_ES_HOST: 'es'
#     AWS_ACCESS_KEY_ID: fake
#     AWS_SECRET_ACCESS_KEY: fake
#     AWS_SESSION_TOKEN: fake

#   script:
#     - apk add --no-cache bash python3
#     - cd esimport_datadog
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - >
#       python3 -m pytest
#       -x
#       --cov=esimport_datadog
#       --cov-report=term-missing
#       tests
#   coverage: '/esimport_datadog.py\s+\d+\s+\d+\s+(\d+%)/'

esimport_datadog_deploy_staging:
  stage: deploy_ecs_image_staging
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli
    - echo "export AWS_ACCESS_KEY_ID=$staging_AWS_ACCESS_KEY_ID" > variables-staging
    - echo "export AWS_SECRET_ACCESS_KEY=$staging_AWS_SECRET_ACCESS_KEY" >> variables-staging
    - echo "export AWS_REGION=us-west-2" >> variables-staging
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$staging_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-staging
  script:
    - source ./variables-staging
    - cd lambdas/esimport_datadog
    # EAST deploy
    - bash ./deploy.sh
      esimport-datadog-monitor-us-east-1
      ${STAGING_LAMBDA_S3_BUCKET_EAST}
      ${STAGING_DATADOG_LOOKBACK_X_MINUTES}
      ${STAGING_ES_CLUSTER_EAST}
      ${staging_SENTRY_DSN}
      ${STAGING_DATADOG_API_KEY}
      us-east-1
      ${STAGING_ROLE_ARN}
      ${DEPLOYMENT_SERVICE_ROLE_ARN}
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "branch_for_staging"

esimport_datadog_deploy:
  stage: production_deploy
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli
    - echo "export AWS_ACCESS_KEY_ID=$prod_AWS_ACCESS_KEY_ID" > variables-prod
    - echo "export AWS_SECRET_ACCESS_KEY=$prod_AWS_SECRET_ACCESS_KEY" >> variables-prod
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$prod_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-prod
  script:
    - source ./variables-prod
    - cd lambdas/esimport_datadog
    # WEST deploy
    - bash ./deploy.sh
      esimport-datadog-monitor-us-west-2
      ${PROD_LAMBDA_S3_BUCKET_WEST}
      ${PROD_DATADOG_LOOKBACK_X_MINUTES}
      ${PROD_ES_CLUSTER_WEST}
      ${SENTRY_DSN}
      ${PROD_DATADOG_API_KEY}
      us-west-2
      ${PROD_ROLE_ARN}
      ${DEPLOYMENT_SERVICE_ROLE_ARN}
    # EAST deploy
    - bash ./deploy.sh
      esimport-datadog-monitor-us-east-1
      ${PROD_LAMBDA_S3_BUCKET_EAST}
      ${PROD_DATADOG_LOOKBACK_X_MINUTES}
      ${PROD_ES_CLUSTER_EAST}
      ${SENTRY_DSN}
      ${PROD_DATADOG_API_KEY}
      us-east-1
      ${PROD_ROLE_ARN}
      ${DEPLOYMENT_SERVICE_ROLE_ARN}
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "master"

# esimport_retention_unit_test:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - >
#       python3 -m pytest tests/unit_tests -x
#       --cov=esimport_retention_core
#       --cov-report=term-missing
#   coverage: '/esimport_retention_core.py\s+\d+\s+\d+\s+(\d+%)/'

# esimport_retention_integration_test:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install awscli
#     - pip3 install -r ./requirements.txt
#     - pip3 install -r ./dev-requirements.txt
#     - bash run-integration-tests.sh
#   coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'

# esimport_retention_deploy:
#   stage: esimport_retention
#   when: manual
#   script:
#     - apk add --no-cache python3
#     - cd esimport_retention
#     - pip3 install awscli
#     - >
#       bash ./deploy.sh \
#       <CloudFormation stack name> \
#       <S3 Bucket Name, to store lambda function code> \
#       <Retention policy in months> \
#       <ES endpoints/urls, comma separated strings> \
#       <Sentry dsn> \
#       <Indices prefixes, comma separated strings> \
#       <Snapshot repo name>
#       <Desired LOGLEVEl>

lambda_delete_account_docs_staging:
  # deploy 'lambdas/delete_old_accounts_docs'
  # only deploy to one region on staging
  stage: deploy_ecs_image_staging
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli

    - echo "export AWS_ACCESS_KEY_ID=$staging_AWS_ACCESS_KEY_ID" > variables-staging
    - echo "export AWS_SECRET_ACCESS_KEY=$staging_AWS_SECRET_ACCESS_KEY" >> variables-staging
    - echo "export TEMP_ARTIFACT_BUCKET=$STAGING_LAMBDA_S3_BUCKET_EAST" >> variables-staging
    - echo "export ES_HOST=$staging_ES_CLUSTER_WEST" >> variables-staging
    - echo "export DD_API_KEY=$staging_DD_API_KEY" >> variables-staging
    - echo "export ES_CLUSTER_EAST_ARN=$staging_ES_CLUSTER_WEST_ARN" >> variables-staging
    - echo "export ES_CLUSTER_WEST_ARN=$staging_ES_CLUSTER_WEST_ARN" >> variables-staging
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$staging_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-staging
  script:
    - |
      source ./variables-staging

      export AWS_REGION=us-east-1
      cd lambdas/delete_old_accounts_docs
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET $ES_HOST $DD_API_KEY
  when: manual
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"
    - if: $CI_COMMIT_BRANCH == "branch_for_staging" || $CI_COMMIT_BRANCH == "master"

lambda_delete_account_docs:
  # deploy 'lambdas/delete_old_accounts_docs'
  # deploy to two regions on prod, us-east-1 & us-west-2
  stage: deploy_ecs_image_prod
  before_script:
    - apt-get update && apt-get install --no-install-recommends --yes python3-pip curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli

    - echo "export AWS_ACCESS_KEY_ID=$prod_AWS_ACCESS_KEY_ID" > variables-prod
    - echo "export AWS_SECRET_ACCESS_KEY=$prod_AWS_SECRET_ACCESS_KEY" >> variables-prod
    - echo "export TEMP_ARTIFACT_BUCKET_EAST=$PROD_LAMBDA_S3_BUCKET_EAST" >> variables-prod
    - echo "export TEMP_ARTIFACT_BUCKET_WEST=$PROD_LAMBDA_S3_BUCKET_WEST" >> variables-prod
    - echo "export ES_HOST_EAST=$PROD_ES_CLUSTER_EAST" >> variables-prod
    - echo "export ES_HOST_WEST=$PROD_ES_CLUSTER_WEST" >> variables-prod
    - echo "export DD_API_KEY=$PROD_DATADOG_API_KEY" >> variables-prod
    - echo "export ES_CLUSTER_EAST_ARN=$prod_ES_CLUSTER_EAST_ARN" >> variables-prod
    - echo "export ES_CLUSTER_WEST_ARN=$prod_ES_CLUSTER_WEST_ARN" >> variables-prod
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$prod_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-prod

  script:
    - |
      source ./variables-prod

      cd lambdas/delete_old_accounts_docs

      export AWS_REGION=us-east-1
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET_EAST $ES_HOST_EAST $DD_API_KEY
      export AWS_REGION=us-west-2
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET_WEST $ES_HOST_WEST $DD_API_KEY
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "master"

sqs_consumer_staging:
  # Deploys 'lambdas/sqs_consumer'
  # on one region us-east-1 as its staging
  stage: deploy_ecs_image_staging
  image: "python:3.10"
  before_script:
    - apt-get -y apt-get update && apt-get -y install curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli

    - echo "export AWS_ACCESS_KEY_ID=$staging_AWS_ACCESS_KEY_ID" > variables-staging
    - echo "export AWS_SECRET_ACCESS_KEY=$staging_AWS_SECRET_ACCESS_KEY" >> variables-staging
    - echo "export TEMP_ARTIFACT_BUCKET_EAST=$STAGING_LAMBDA_S3_BUCKET_EAST" >> variables-staging
    - echo "export ES_HOST_WEST=$staging_ES_CLUSTER_WEST" >> variables-staging
    - echo "export LAMDA_ROLE_ARN=$STAGING_ROLE_ARN" >> variables-staging
    - echo "export SENTRY_DSN=$staging_SENTRY_DSN" >> variables-staging
    - echo "export SNS_TOPIC_ARN=$staging_SNS_TOPIC_ARN" >> variables-staging
    - echo "export DPSK_SNS_TOPIC_ARN=$staging_DPSK_SNS_TOPIC_ARN" >> variables-staging
    - echo "export SNS_TOPIC_REGION=$staging_SNS_TOPIC_REGION" >> variables-staging
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$staging_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-staging
  script:
    - |
      source ./variables-staging
      cd lambdas/sqs_consumer

      export STACK_NAME=esimport-serverless-us-east-1
      export AWS_REGION=us-east-1
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET_EAST $LAMDA_ROLE_ARN $SNS_TOPIC_ARN $DPSK_SNS_TOPIC_ARN $ES_HOST_WEST $SENTRY_DSN $SNS_TOPIC_REGION
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "branch_for_staging"

sqs_consumer_prod:
  stage: deploy_ecs_image_prod
  image: "python:3.10"
  before_script:
    - apt-get -y apt-get update && apt-get -y install curl git
    - pip3 --no-cache-dir install awscli aws-sam-cli

    - echo "export AWS_ACCESS_KEY_ID=$prod_AWS_ACCESS_KEY_ID" > variables-prod
    - echo "export AWS_SECRET_ACCESS_KEY=$prod_AWS_SECRET_ACCESS_KEY" >> variables-prod
    - echo "export TEMP_ARTIFACT_BUCKET_EAST=$PROD_LAMBDA_S3_BUCKET_EAST" >> variables-prod
    - echo "export TEMP_ARTIFACT_BUCKET_WEST=$PROD_LAMBDA_S3_BUCKET_WEST" >> variables-prod
    - echo "export ES_HOST_EAST=$PROD_ES_CLUSTER_EAST" >> variables-prod
    - echo "export ES_HOST_WEST=$PROD_ES_CLUSTER_WEST" >> variables-prod
    - echo "export LAMBDA_ROLE_ARN=$PROD_ROLE_ARN" >> variables-prod
    - echo "export SENTRY_DSN=$prod_SENTRY_DSN" >> variables-prod
    - echo "export SNS_TOPIC_ARN=$prod_SNS_TOPIC_ARN" >> variables-prod
    - echo "export DPSK_SNS_TOPIC_ARN=$prod_DPSK_SNS_TOPIC_ARN" >> variables-prod
    - echo "export SNS_TOPIC_REGION=$prod_SNS_TOPIC_REGION" >> variables-prod
    - echo "export DEPLOYMENT_SERVICE_ROLE_ARN=$prod_DEPLOYMENT_SERVICE_ROLE_ARN" >> variables-prod
  script:
    - |
      source ./variables-prod
      cd lambdas/sqs_consumer

      # deploy first region us-east-1
      export STACK_NAME=esimport-serverless-us-east-1
      export AWS_REGION=us-east-1
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET_EAST $LAMBDA_ROLE_ARN $SNS_TOPIC_ARN $DPSK_SNS_TOPIC_ARN $ES_HOST_EAST $SENTRY_DSN $SNS_TOPIC_REGION

      # us-west-2 
      export STACK_NAME=esimport-serverless-us-west-2
      export AWS_REGION=us-west-2
      bash ./deploy.sh $TEMP_ARTIFACT_BUCKET_WEST $LAMBDA_ROLE_ARN $SNS_TOPIC_ARN $DPSK_SNS_TOPIC_ARN $ES_HOST_WEST $SENTRY_DSN $SNS_TOPIC_REGION
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "master"
